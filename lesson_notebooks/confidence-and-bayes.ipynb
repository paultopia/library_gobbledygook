{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Confidence Intervals and Bayesian Statistics oh my!\n",
    "- Date: 2019-04-13\n",
    "- Tags: statistics, week13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the readings for week 13, \"The Bayesian New Statistics,\" covers a variety of different approaches to statistics, as contrasted with the standard frequentist hypothesis-testing method. I don't expect you to come out of this class being able to work any of those alternative paradigms, but you should be able to recognize them and understand broadly how they operate.  That article is a very good summary of the landscape, but this supplemental lesson aims to provide a briefer and slightly more basic introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Confidence Intervals vs P-Values\n",
    "\n",
    "One of the ideas in that article is \"new statistics,\" which is roughly meant to capture the move away from p-values and hypothesis tests and toward confidence intervals.  This movement has arisen in recent years mainly because of the many ways in which hypothesis tests and p-values have been misused. The idea is that reporting a confidence interval is a clearer expression of the range of uncertainty of the thing you're trying to estimate. \n",
    "\n",
    "So what's a confidence interval?  Roughly speaking, it's the range equivalent of a p-value---a lower bound and an upper bound for a parameter constructed to achieve a specified degree of confidence (typically 95%).\n",
    "\n",
    "Interpreting confidence intervals can be difficult, however.  The standard interpretation of them is \"if we took a bunch of samples from the population, then calculated a 95% confidence interval from each of the samples, we'd expect to see the population (true) parameter within 95% of the confidence intervals in our hypothetical creation of many samples.  Here's [a concise definition from some epidemologists](https://www.ncbi.nlm.nih.gov/pubmed/27184382) and here's [an explanation of common misinterpretations of confidence intervals as well as p-values](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4877414/).\n",
    "\n",
    "Statsmodels reports confidence intervals for regression coefficients.  Let's take a look at them, and then I'm going to show you one (fairly brutish---there are more sophisticated and accurate ways to do it in the real world) way to create your own via bootstrapping.  \n",
    "\n",
    "First, let's simulate some data.  We're going to pretend that heights are normally distributed around 6 feet with a wide standard deviation (they're not), and then we're going to pretend that shoe sizes are about height in inches/10, with some Gaussian (normally distributed) noise added to represent, say, observation error, or other factors leading to shoe size other than height (diet? amount of soccer played as a child?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "np.random.seed(90210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = np.random.normal(loc=72.0, scale=5.0, size=500)\n",
    "shoe_sizes = [(height / 10) + np.random.normal(scale=2.0) for height in heights]\n",
    "heights = heights.astype(int)\n",
    "shoe_sizes = np.array(shoe_sizes).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a simulated sample of heights and shoe sizes, of size 500, and we made them integers (which I believe should just truncate the decimals, though I could be misremembering how Numpy does it, and it might round---probably truncates though) to add some more noise.  Now let's wrap them up in a Data Frame and look at a regression coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   shoe   R-squared:                       0.070\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     37.39\n",
      "Date:                Sat, 13 Apr 2019   Prob (F-statistic):           1.95e-09\n",
      "Time:                        14:09:45   Log-Likelihood:                -1050.2\n",
      "No. Observations:                 500   AIC:                             2104.\n",
      "Df Residuals:                     498   BIC:                             2113.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.1321      1.270     -0.891      0.373      -3.628       1.363\n",
      "height         0.1089      0.018      6.115      0.000       0.074       0.144\n",
      "==============================================================================\n",
      "Omnibus:                        6.090   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.048   Jarque-Bera (JB):                6.220\n",
      "Skew:                           0.268   Prob(JB):                       0.0446\n",
      "Kurtosis:                       2.894   Cond. No.                     1.02e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"height\": heights, \"shoe\": shoe_sizes})\n",
    "\n",
    "reg = sm.ols(formula='shoe ~ height', data=df).fit()\n",
    "print(reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note here (ignoring the silliness about the condition number, which is related to troubles that statsmodels has had with this calculation).  \n",
    "\n",
    "1.  Our coefficient looks about right---pretty close to .1, which is what we would expect given that how the data were simulated. \n",
    "\n",
    "2.  In the right-most two columns of the middle section of the table, we see confidence intervals---in this case, a 95% confidence interval goes from 0.074 to 0.144. \n",
    "\n",
    "Now let's bootstrap a confidence interval!  This can be computationally intensive, and I'm impatient, so in order to do this, I'm going to *try* to make it faster by calculating the regression coefficients directly rather than messing around with library code that calculates a bunch of other stuff, and puts into a DataFrame (or manipulates statsmodels in other ways to avoid going through slow Pandas) etc. etc.  This might be a terrible mistake, though, as hand-written code by me is almost always slower than library code.  Still, let's see what happens. \n",
    "\n",
    "Mathematically, we can calculate a simple (one independent variable) linear regression coefficient with the following equation, where \\bar{x} is the mean of x and subscripts index the individual points in the dataset: \n",
    "\n",
    "$$\\beta = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2}$$\n",
    "\n",
    "This is pretty trivial to reduce to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(pairs):\n",
    "    x = [point[0] for point in pairs]\n",
    "    mean_x = np.mean(x)\n",
    "    y = [point[1] for point in pairs]\n",
    "    mean_y = np.mean(y)\n",
    "    numerator = 0\n",
    "    for point in pairs:\n",
    "        numerator += (point[0] - mean_x) * (point[1] - mean_y)\n",
    "    denominator = np.sum([np.square(item - mean_x) for item in x])\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My function takes a single array of (x, y) points, representing a single data point, which we can get using Python's built-in `zip()` function.  Let's make sure I did the math right by comparing the results of this function to the built-in statsmodels function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10885151617958266\n"
     ]
    }
   ],
   "source": [
    "pairs = np.array(list(zip(heights, shoe_sizes)))\n",
    "\n",
    "coefficient = beta(pairs)\n",
    "print(coefficient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good to me!  It's the same, minus some rounding difference.  Now we can do some bootstrapping.  We're going to randomly resample, with replacement (so they're different) from our existing sample to generate a lot of synthetic datasets, and then we're going to generate a 95% confidence interval by taking the 2.5%ile and the 97.5%ile of the betas calculted from each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07409887356837877\n",
      "0.14371195712135248\n"
     ]
    }
   ],
   "source": [
    "def resample(pairs):\n",
    "    size = len(pairs)\n",
    "    indices = np.random.choice(a=size, size=size, replace=True)\n",
    "    sample = pairs[indices]\n",
    "    return beta(sample)\n",
    "bootstrap_samples = np.array([resample(pairs) for x in range(10000)])\n",
    "print(np.percentile(bootstrap_samples, 2.5))\n",
    "print(np.percentile(bootstrap_samples, 97.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we got a result very close to what statsmodels calculated for us (again, basically indistinguishable, modulo rounding)!  So, that's confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "library_gobbledygook",
   "language": "python",
   "name": "library_gobbledygook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
